# libraries
import yaml
import pandas as pd
import os
from snakemake.utils import validate, min_version

import argparse
import yaml, json
import csv
import os
import sys
from collections.abc import Mapping
from string import Template

##### utility functions #####
def get_raw_bams(wildcards):
    return str.split(samples[wildcards.sample]["raw_bams"])

def update(d, u):
    """
    Recursively updates the entries in a given dictionary
    :param d: The dictionary to be updated
    :param u: The values which will be added to the input dictionary
    :return: Updated dictionary
    """
    for k, v in u.items():
        if isinstance(v, Mapping):
            d[k] = update(d.get(k, {}), v)
        else:
            d[k] = v
    return d

def configurator(default, project_config):

    # Read in project specific config file
    specific = {}

    with open(project_config, 'r') as stream:
        try:
            specific = yaml.safe_load(stream)
        except yaml.YAMLError as exception:
            sys.stderr.write(str(exception))
            
    update(default, specific)

    # rename the updated dictionary
    config = default
    
#     print("config in function")
#     print(config)

    # Create project directory
    project_path = config['project_path']
    if not os.path.exists(project_path):
        os.mkdir(project_path)

    project_genome = config['genome']
    project_genome_size = config['genome_sizes'][project_genome]
    inputs_dict = {'atacseq.project_name': config['project_name'],
                   'atacseq.project_path': config['project_path'],
                   'atacseq.project_config': config['project_config'],
                   'atacseq.email': config['email'],
                   'atacseq.genome': project_genome,
                   'atacseq.adapter_fasta': config['adapter_fasta'],
                   'atacseq.bowtie2_index': config['bowtie2_index'][project_genome],
                   'atacseq.chromosome_sizes': config['chromosome_sizes'][project_genome],
                   'atacseq.blacklisted_regions': config['blacklisted_regions'][project_genome],
                   'atacseq.whitelisted_regions': config['whitelisted_regions'][project_genome],
                   'atacseq.unique_tss': config['unique_tss'][project_genome],
                   'atacseq.mitochondria_name': config['mitochondria_names'][project_genome],
                   'atacseq.regulatory_regions': config['regulatory_regions'][project_genome],
                   'atacseq.sample_annotation': config['sample_annotation'],
                   'atacseq.annotation_metadata': config['annotation_metadata'],
                   'atacseq.plot_by': config['plot_by'],
                   'atacseq.peak_support_threshold': config['peak_support_threshold'],
                   'atacseq.proportion': config['proportion'],
                   'atacseq.min_group': config['min_group'],
                   'atacseq.genome_fasta': config['genome_fasta'][project_genome],
                   'atacseq.gencode_gtf': config['gencode_gtf'][project_genome],
                   'atacseq.regulatory_build_gtf': config['regulatory_build_gtf'][project_genome],
                   'atacseq.split_by': config['split_by'],
                   'atacseq.HVR_percentage': config['HVR_percentage'],
                   'atacseq.downstream_analysis': config['downstream_analysis'],
                   'atacseq.tss_size': config['tss_size'],
                   'atacseq.proximal_size_up': config['proximal_size_up'],
                   'atacseq.proximal_size_dn': config['proximal_size_dn'],
                   'atacseq.distal_size': config['distal_size'],
                   }
    if 'adapter_sequence' in config:
        inputs_dict['atacseq.adapter_sequence'] = config['adapter_sequence']
    sas_file = config['sample_annotation']
    sas_dict = {}
    with open(sas_file, 'r') as sas:
        reader = csv.DictReader(sas, dialect='excel')
        for row in reader:
            if 'sample_name' in row:
                if row['sample_name'] in sas_dict:
                    sas_dict[row['sample_name']].append(row)
                else:
                    sas_dict[row['sample_name']] = [row]

    inputs_dict['atacseq.sample_list'] = list(sas_dict.keys())

    sample_dicts = {}
    for sample in sas_dict:
        sample_dict = {'sample_name': sample,
                       'read_type': sas_dict[sample][0]['read_type'],
                       'organism': sas_dict[sample][0]['organism'],
                       'skip_preprocess': sas_dict[sample][0]['skip_preprocess'],
                       'genome': project_genome,
                       'genome_size': project_genome_size,
                       'raw_bams': ''}

        # skip this sample if indicated (note: it is still in the sample list of the project dict)
        if sample_dict['skip_preprocess'] == "yes":
            continue
        
        row_list = sas_dict[sample]
        number_of_rows = len(row_list)
        bam_sources = []
        raw_size_mb = 0
        for i in range(number_of_rows):
            if 'data_source' in row_list[i] and row_list[i]['data_source'] != '':
                source_template = config['data_sources'][row_list[i]['data_source']]
                source = source_template.format(**row_list[i])
                if os.path.exists(source):
                    bam_sources.append(source)
                    if(os.path.exists(source)):
                        source_stats = os.stat(source)
                        raw_size_mb += int(source_stats.st_size / (1024 * 1024))
                else:
                    print('WARNING: Could not locate {}'.format(source))
        if len(bam_sources) == 0:
            print('WARNING: Could not locate any raw data files for sample {}, skipping.'.format(sample))
        else:
            sample_dict['raw_bams'] = ' '.join(bam_sources)
            sample_dict['raw_size_mb'] = raw_size_mb
            sample_dicts[sample]=sample_dict
    
    return inputs_dict, sample_dicts

##### set minimum snakemake version #####
min_version("6.0.3")

##### setup report #####
report: "report/workflow.rst"
    
#### setup workdir (necessary for portability) ####
# todo: put in pipeline config: pipeline_dir: "/path/to/pipeline"
# workdir: config['pipeline_dir']

##### set & load config and sample annotation sheets #####
configfile: os.path.join("config","pipeline_config.yaml")

# print('config before')
# print(config)

# run configurator to get pipeline configs & sample annotations
config, samples = configurator(config, config["project_config"])

# print('config after')
# print(config)
# print(samples)

##### set global variables
results_dir = os.path.join(config["atacseq.project_path"], "atacseq_results")

annotation_metadata=pd.read_csv(config["atacseq.annotation_metadata"], index_col=0)

data_splits = ['all']
if config["atacseq.split_by"]!='':
    data_splits.extend(list(annotation_metadata[config["atacseq.split_by"]].unique()))
    
steps = ['counts','filtered','normTMM','normCQN','normTMM_HVR', 'normCQN_HVR']

# cluster parameters
partition="shortq"
mem="32G"
threads=2

# calculate parameters (for misc tasks)
tss_slop = 2000
noise_lower = 100
noise_upper = ( tss_slop * 2 ) - noise_lower
double_slop = ( tss_slop * 2 )


##### target rules #####

# generates a HTML report from all the results as self-contained .zip archive for sharing
rule all:
    input:
        os.path.join(config["atacseq.project_path"],"atacseq_report"), # for the inclusion into snakemake report
        project_config_file=report(config["atacseq.project_config"], caption="report/project_configfile.rst", category="Configuration"),
        sample_annotation_file=report(config["atacseq.sample_annotation"], caption="report/sample_annotation.rst", category="Configuration"),
        annotation_metadata_file=report(config["atacseq.annotation_metadata"], caption="report/annotation_metadata.rst", category="Configuration"),
        dimred_plots=expand(
            os.path.join(config["atacseq.project_path"],'{split}', 'unsupervised_analysis',"{dimred}_{split}_{step}_{plot_by_variable}.svg"),
            plot_by_variable=config['atacseq.plot_by'], 
            dimred=["UMAP","PCA"],
            split=data_splits,
            step=steps) if config["atacseq.downstream_analysis"]==1 else os.path.join(config["atacseq.project_path"],"atacseq_report"),
        meanvar_plots=expand(os.path.join(config["atacseq.project_path"],'{split}',"mean_variance_analysis","mean_variance_{split}_{step}.svg"),split=data_splits, step=steps) if config["atacseq.downstream_analysis"]==1 else os.path.join(config["atacseq.project_path"],"atacseq_report"),
        consensus_regions_annotation=os.path.join(config["atacseq.project_path"],'all',"consensus_regions_annotation.csv"),
    output:
        atacseq_report=os.path.join(config["atacseq.project_path"],"{}_report.zip".format(config["atacseq.project_name"])),
    params:
        # cluster parameters
        partition=partition,
    threads: threads
    resources:
        mem=mem,
    log:
        os.path.join("logs","rules","all.log")
    shell:
        """
        snakemake --unlock
        snakemake --configfile {config[atacseq.project_config]} --report {output.atacseq_report}
        """
# mail -s "snakemake ATAC-seq pipeline for {config[atacseq.project_name]} finished" {config[atacseq.email]}

##### load rules #####

include: "rules/install_homer.smk"
include: "rules/bowtie2_align.smk"
include: "rules/peak_calling.smk"
include: "rules/misc_tasks.smk"
include: "rules/multiqc.smk"
include: "rules/quantification.smk"
include: "rules/processing.smk"
include: "rules/dimred.smk"
include: "rules/region_annotation.smk"